\chapter{Recommendations} \label{reco}
Due to the broad nature of this research various recommendations can be made regarding new research topics and practical implementations. These could improve existing methods, extent methods for the classification as described in section \ref{sec:clas}, or be possibly developed into new solutions.\\

\section{Optical Data}
Regarding the use of univariate image differencing for the detection of change based on \ac{rgb} or \ac{hsv} values could be improved in various ways. First of all, an approach as described by \citet{Yun2015}, in which the coherence between datasets is used, could also be advisable for applications based on multi-layered optical images. In that case multiple datasets should be pre-emptively collected, to allow for the creation of coherence maps. This requires pre-emptive resource investments. However, these would allow for description of the coherence between pixels, which could be used as an indicator of damage. Practically, this approach might incur more opposition due to the investment necessary. However, especially regarding repetitive and predictable disasters, like hurricanes, this could be a benefit for all involved in the humanitarian operation later.
Secondly, the datasets could be subtracted in multiple bands, this would allow for more data to be used in the detection of change and or damage. To achieve this, a new method would need to be developed capturing various features of the date to capture the coherence. A \ac{cnn} or other convolution algorithm would allow for the description of the pixel coherence to be used for classification.
Lastly, the change indicator layers as presented in section \ref{sec:Ryun}, figure \ref{fig:MidComp}, could provide extra indication of damage in case visual interpretation is used. This as it highlights possible change, which would make manual classification more accessible. Which is especially useful in the possible crowd-sourcing of this kind of information using approaches similar to Missing Maps \footnote{\url{http://www.missingmaps.org/}}.\\

\noindent In the use of \ac{cnn} for damage classification, various improvements could be made. A single implementation architecture for damage detection or classification is hard to establish. This is due to  data variability caused by variance in the sensors, conditions, or other exterior influences. To achieve a result for all datasets, a library with various datasets within would need to be created. This approach, similar to ImageNet \footnote{\url{http://www.image-net.org/}}, would allow \ac{ngo} to develop tools based on data available from a diverse range of disaster, all oriented on the classification of damage. With this database, new networks could be designed to cope with various inputs and variations in other exterior influence. An existing database with known damage identified on post-event imagery could also inspire other technologies for damage classification.\\

\noindent Furthermore, would a \ac{cnn} approach be helped by improved creation of the features. This could also be achieved through more machine learning. If it would be possible for a Neural Network approach to identify buildings on a pre-disaster image, it would be possible to create clear outlines for use on OpenStreetMap as well as within operations using \ac{cnn}s for the classification or detection of damage. This also reflects back to the geo-referencing of imagery. Newer techniques allow for faster and more accurate data collection, however the smaller packages and cheaper sensors do not allow for perfect geo-referencing. An improvement in the alignment of imagery and the geo-referencing of optical imagery would be beneficial for the results of various methods.

\section{\ac{sar} Data}
The use of \ac{sar} in both approaches is limited by the resolution of the input. Higher resolution inputs, or lower resolution expected output, could allow the use of \ac{cnn} for all datasets. However it must be noted that it can be hard to distinguish features on \ac{sar} data. This property would transfer to the use of machine learning, specifically \ac{cnn}s, as the method is based on the use of distinguishable features for classification.  A further deep-dive into the methodology devised by \citet{Yun2015} could also uncover possible areas of improvement. Various research around the world have been able to detect millimetre changes in static objects using satellite \ac{sar} data \citep{SOUSA2010181}.\\ 

\noindent Another solution for the use of lower resolution data is an aggregation of damage after the pixels have been classified. In this case, if a building is covered by 4 pixels partly, an aggregate of these pixels would be subscribed to the building. If in that case one of the pixels is classified as damaged and overlaps the building by 25\%, this building would be considered damaged for 25\%. A similar approach would be valid for use with the optical data sets in which it would be the amount of pixels classified as damaged relative to the total amount of pixels within the building bounds.

\section{Data Combination}
While this research only considered datasets separately, the combination of datasets could provide new possibilities for the determination of damage. As mentioned in section \ref{sec:disc}, the advantages of satellite based \ac{sar}, in particular the operational agility and large coverage area, are complementary to the \ac{vhr} \ac{uav} imagery, which are limited in coverage area but provide more information about damage. In the fusion of these datasets, and the possible addition of others, combination of methods could be used to fully- or semi- automatically determine the damage extent after a disaster. 

\section{Disaster Specific Properties}
This research considered general approaches to the detection and classification of damage. This is based on the premise that building damage is generally similar between disasters, however, it can be noted that various disasters might have specific damage patterns around buildings. The manual method proposed by \citet{Okada2000} is based on the premise of building damage patterns to determine the extend of the area affected. An automated approach could use similar indicators for remotely sensed data. An example of damage patterns surrounding buildings could be the debris spread observed after a hurricane, where debris is scattered around a building in the direction of the prevailing winds; compared to earthquake damage, where debris is usually less scattered and more concentrated on the building footprint.

\section{Method Assessment Framework}
The pre-existing conditions regarding damage classification and information needs within humanitarian aid changes constantly. A more social approach to the problem would allow for clearer definitions of needs and possible holes in the information provision with regards to remotely sensed data. An implementation review of the approach used by Copernicus and UNOSAT, which would focus on the use of the information, would allow for understanding of their products. This would further allow the introduction of new data sources in the programmes of \ac{ngo}, which in turn would favourably influence the research with regards to implementation possibilities. \\

\noindent In this research the focus was placed on a part of the \ac{drm} activity cycle. However, information needs vary within this cycle as well. Other methods, including predicting approaches, would be useful in the various stages of the \ac{drm} activity cycle for humanitarian organisations. Examples of this include the work done by \citet{Lint2016} and \cite{Bulte2017}, in which predictive models estimate the damage after typhoons and earthquakes. Similarly an approach in which verified data from the field can be used to train new methods for more accurate damage classification in later stages of a disaster, allowing for better accuracy on a higher resolution.\\

\noindent Other methods identified in this research, could transfer better to the datasets used. More research regarding their capabilities would allow for the development of new practicable methods. These methods in combination with the knowledge from this research, might be capable of the classification of damage, automatically or semi-automatically. Lastly, the use of semi-automated methods could also be a practical approach. As disasters vary from location, time, and intensity, a flexible human approach could benefit the method. In such an approach some steps are identified by humans, so a-priori knowledge can be supplied to the automatic classification tools. This synergy would allow for the best of both approaches, the flexible insights of a human and the meticulous repetitive approach of machine learning, allowing for faster creation of information. This would not be a troublesome practical approach as most disaster datasets have to be scrambled from various sources; human involvement is - for now - indispensable.

\section{Comparison of Results}
The use of the Cohen Kappa Coefficient, F1 Score, and Confusion Matrix are non optimal indicators for the use in humanitarian circumstances. It would benefit the humanitarian organisations if the risk of false negatives, regarding building damage would be minimised. This would ensurethat everybody in need of assistance receives aid. Another minimisation technique might therefore be beneficial for these problems. This could be achieved by the addition of weights to certain classes, in which it is more important that these are classified correctly. A certain distinction is still necessary and the balance should not be moved to classifying as many buildings as possible as damaged, as this would defy the goal of a damage classification method for disaster impact. This could be done with the F1-Score mentioned in section \ref{sec:interrater} as well as other classification techniques.