\chapter*{Abstract}
In the second half of the 20\textsuperscript{th} and beginning of the 21\textsuperscript{st} century the amount of natural disasters has increased rapidly. Due to this rise in occurrences, more people are affected. An important indicator for people affected is the amount of damage to buildings. To gather this information aid workers now have to go into the field to gather data on the amount of destruction. In response to the possible dangers these people encounter in the field, remote sensing and analysis techniques have been developed for automated damage detection. However, due to various limitations on the implementation, these techniques are not yet widely adopted in emergency response and humanitarian aid.\\

\noindent This work compares two methods and two data sources for the detection of building damage. The methods are evaluated on their accuracy and implementability within humanitarian aid in disaster situations. The main methods considered are equalisation of histograms of pre-event and post-event imagery, followed by Univariate Image Differencing; and a convolutional neural network on features withdrawn from post-event imagery, using OpenStreetMap data. Remotely sensed data sources considered are synthetic aperture radar and very high resolution optical imagery. All results are analysed and compared to current standards in damage detection. \\

\noindent From the results it can be concluded that more research is required for a practical implementation of deep learning techniques. The constraint posed by the requirement of large datasets, make these methods impracticable without sufficient preparation and resources. More simpler methods, like Univariate Image Differencing, can be validated on smaller ground-truth datasets, and are therefore easier in implementation when resources are limited. The possible accuracy increase of deep learning methods does, at this moment, not outweigh the ease of an elementary differencing approach.